"""Tests for the fixer module â€” THE KEY DIFFERENTIATOR."""

import pytest

from revibe.analyzer import analyze_files
from revibe.duplicates import find_all_duplicates
from revibe.fixer import Fix, FixerEngine, FixPlan, generate_fix_plan
from revibe.metrics import aggregate_metrics
from revibe.scanner import scan_codebase
from revibe.smells import detect_all_smells


class TestFixPlan:
    """Tests for FixPlan dataclass."""

    def test_priority_filters(self):
        fixes = [
            Fix(priority="CRITICAL", title="Fix 1", description="", prompt=""),
            Fix(priority="HIGH", title="Fix 2", description="", prompt=""),
            Fix(priority="MEDIUM", title="Fix 3", description="", prompt=""),
            Fix(priority="LOW", title="Fix 4", description="", prompt=""),
        ]

        plan = FixPlan(
            fixes=fixes,
            codebase_path=".",
            health_score=50,
            risk_level="ELEVATED",
            generated_at="2026-01-31T00:00:00",
        )

        assert len(plan.critical_fixes) == 1
        assert len(plan.high_fixes) == 1
        assert len(plan.medium_fixes) == 1
        assert len(plan.low_fixes) == 1


class TestFixerEngine:
    """Tests for the FixerEngine class."""

    def test_generate_fixes_no_tests(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)

        assert isinstance(plan, FixPlan)
        assert len(plan.fixes) > 0

        # Should have a test-related fix
        test_fix = next(
            (f for f in plan.fixes if "test" in f.title.lower()),
            None
        )
        assert test_fix is not None
        assert test_fix.priority == "CRITICAL"

    def test_generate_fixes_healthy(self, healthy_project):
        files = scan_codebase(str(healthy_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(healthy_project))
        plan = fixer.generate_fixes(metrics)

        # Healthy project should have fewer/no critical fixes
        critical_count = len(plan.critical_fixes)
        assert critical_count <= 1  # May have minor issues

    def test_generate_fixes_with_duplicates(self, bloated_project):
        files = scan_codebase(str(bloated_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(bloated_project))
        plan = fixer.generate_fixes(metrics)

        # Should detect duplicates
        duplicate_fix = next(
            (f for f in plan.fixes if "duplicate" in f.title.lower()),
            None
        )
        assert duplicate_fix is not None


class TestRenderMarkdown:
    """Tests for markdown rendering."""

    def test_render_markdown_valid(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        markdown = fixer.render_markdown(plan)

        # Check markdown structure
        assert "# Revibe Fix Instructions" in markdown
        assert "Generated by Revibe" in markdown
        assert "Health Score:" in markdown
        assert "```" in markdown  # Should have code blocks for prompts

    def test_render_markdown_contains_file_references(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        markdown = fixer.render_markdown(plan)

        # Prompts should reference actual files from the scan
        for fix in plan.fixes:
            if fix.affected_files:
                # At least one file should be mentioned
                assert any(f in markdown for f in fix.affected_files[:3])

    def test_render_markdown_priority_order(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        markdown = fixer.render_markdown(plan)

        # Critical should appear before Medium if both exist
        if plan.critical_fixes and plan.medium_fixes:
            critical_pos = markdown.find("CRITICAL")
            medium_pos = markdown.find("MEDIUM")
            if critical_pos >= 0 and medium_pos >= 0:
                assert critical_pos < medium_pos


class TestRenderCursorRules:
    """Tests for .cursorrules rendering."""

    def test_render_cursor_rules_valid(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        rules = fixer.render_cursor_rules(plan)

        # Check rules structure
        assert "# Revibe Rules" in rules
        assert "Health Score:" in rules
        assert "Priority fixes" in rules or "General rules" in rules

    def test_render_cursor_rules_has_actionable_items(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        rules = fixer.render_cursor_rules(plan)

        # Should have rule items
        assert "- " in rules  # Markdown list items
        # Should have action words
        action_words = ["ALWAYS", "NEVER", "PREFER", "DO NOT", "CONSIDER"]
        assert any(word in rules for word in action_words)


class TestRenderClaudeMd:
    """Tests for CLAUDE.md rendering."""

    def test_render_claude_md_valid(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        claude_md = fixer.render_claude_md(plan)

        # Check structure
        assert "## Code Health Notes (Revibe)" in claude_md
        assert "Health score:" in claude_md
        assert "risk" in claude_md.lower()

    def test_render_claude_md_concise(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)
        claude_md = fixer.render_claude_md(plan)

        # Should be concise (not a huge document)
        lines = claude_md.strip().split("\n")
        assert len(lines) <= 15  # Should be a brief section


class TestGenerateFixPlan:
    """Tests for the generate_fix_plan convenience function."""

    def test_generate_fix_plan_works(self, healthy_project):
        files = scan_codebase(str(healthy_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        plan = generate_fix_plan(str(healthy_project), metrics)

        assert isinstance(plan, FixPlan)
        assert plan.codebase_path == str(healthy_project)
        assert 0 <= plan.health_score <= 100

    def test_empty_codebase_no_crash(self, empty_project):
        files = scan_codebase(str(empty_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        # Should not crash on empty codebase
        plan = generate_fix_plan(str(empty_project), metrics)

        assert isinstance(plan, FixPlan)
        # May have no fixes for empty project
        assert isinstance(plan.fixes, list)


class TestPromptsAreSelfContained:
    """Tests ensuring prompts are self-contained for AI tools."""

    def test_prompts_dont_reference_report(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)

        for fix in plan.fixes:
            prompt = fix.prompt.lower()
            # Prompts should not reference "the report" or similar
            assert "see above" not in prompt
            assert "as shown" not in prompt
            assert "in the report" not in prompt

    def test_prompts_are_actionable(self, no_tests_project):
        files = scan_codebase(str(no_tests_project))
        analyses = analyze_files(files)
        smells = detect_all_smells(analyses)
        duplicates = find_all_duplicates(analyses)
        metrics = aggregate_metrics(files, analyses, smells, duplicates)

        fixer = FixerEngine(str(no_tests_project))
        plan = fixer.generate_fixes(metrics)

        for fix in plan.fixes:
            # Each prompt should have some content
            assert len(fix.prompt) > 50
            # Should contain action words
            action_indicators = ["create", "add", "fix", "test", "remove", "update", "review", "analyze"]
            assert any(word in fix.prompt.lower() for word in action_indicators)
